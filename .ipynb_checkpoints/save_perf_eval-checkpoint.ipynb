{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "afb92ea0-6e1f-41ac-8582-b24fa357ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, warnings, random, requests, datetime, pytz, joblib\n",
    "import functools as ft\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "import pandas_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "319d8383-d776-4904-9c3e-d103d94c151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aafd47bf-81b8-4afc-8d41-213dfd1c9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = time.time()\n",
    "pull_time = datetime.datetime.now()\n",
    "pull_time = pull_time.astimezone(pytz.timezone('America/New_York'))\n",
    "pull_time = pull_time.replace(tzinfo=None)\n",
    "now_time = (str(pull_time.month) + '_' + \n",
    "str(pull_time.day) + '_' +\n",
    "str(pull_time.hour) + ':'  +\n",
    "str(pull_time.minute) + ':' +\n",
    "str(pull_time.second))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c203b09-9e9e-4964-ae5e-ce4d3df1f65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time: 1.1183018684387207 sec'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "# gsutil works on Vertex, but not in a Cloud Function...\n",
    "data_bucket_name = 'pmykola-streaming-projects'\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(data_bucket_name)\n",
    "blobs_all = list(bucket.list_blobs())\n",
    "blobs_specific = list(bucket.list_blobs(prefix='spg-stocks/data'))\n",
    "temp_fnames = [blob.name for blob in blobs_specific]\n",
    "datafiles = ['gs://' + data_bucket_name + '/' + fname for fname in temp_fnames]\n",
    "\n",
    "# datafiles = !gsutil ls gs://pmykola-streaming-projects/spg-stocks/data\n",
    "datafiles = [x for x in datafiles if ('auto_data_last_' in x) & ('pull_time' in x)]\n",
    "f'time: {time.time()-time1} sec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55bfac14-da43-4611-a5b6-cdbbdcb92747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.03382730484008789 sec\n"
     ]
    }
   ],
   "source": [
    "time2 = time.time()\n",
    "tempdf = pd.DataFrame(datafiles, columns=['filename'])\n",
    "tempdf['year'] = 0\n",
    "tempdf['month'] = 0\n",
    "tempdf['day'] = 0\n",
    "# display(tempdf.head())\n",
    "# display(tempdf.iloc[0,:])\n",
    "for i in range(tempdf.shape[0]):\n",
    "    tempdf.loc[i,'year'] = tempdf.loc[i,'filename'].split(\"auto_data_last_\",1)[1][:4]\n",
    "    tail = tempdf.loc[i,'filename'].split(\"pull_time_\",1)[1]\n",
    "    tempdf.loc[i,'month'] = tail.split(\"_\",1)[0]\n",
    "    tempdf.loc[i,'day'] = (tail.split(\"_\",1)[1]).split(\"_\",1)[0]\n",
    "    \n",
    "# display(tempdf.head())\n",
    "\n",
    "tempdf['date'] = pd.to_datetime(tempdf[['year', 'month', 'day']])\n",
    "tempdf.sort_values(by='date', inplace=True)\n",
    "# tempdf = tempdf.tail(4)\n",
    "dates = tempdf.date.copy()\n",
    "dates = [x for x in dates if x > datetime.date(2022, 12, 23)]\n",
    "print(f'time: {time.time()-time2} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6999638-de99-468e-aac9-96ad3f4ad675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2022-12-27 00:00:00'),\n",
       " Timestamp('2022-12-28 00:00:00'),\n",
       " Timestamp('2022-12-29 00:00:00'),\n",
       " Timestamp('2022-12-30 00:00:00'),\n",
       " Timestamp('2023-01-03 00:00:00'),\n",
       " Timestamp('2023-01-04 00:00:00'),\n",
       " Timestamp('2023-01-05 00:00:00'),\n",
       " Timestamp('2023-01-06 00:00:00'),\n",
       " Timestamp('2023-01-09 00:00:00'),\n",
       " Timestamp('2023-01-10 00:00:00'),\n",
       " Timestamp('2023-01-11 00:00:00'),\n",
       " Timestamp('2023-01-12 00:00:00'),\n",
       " Timestamp('2023-01-13 00:00:00'),\n",
       " Timestamp('2023-01-17 00:00:00'),\n",
       " Timestamp('2023-01-18 00:00:00'),\n",
       " Timestamp('2023-01-19 00:00:00'),\n",
       " Timestamp('2023-01-20 00:00:00'),\n",
       " Timestamp('2023-01-23 00:00:00'),\n",
       " Timestamp('2023-01-24 00:00:00'),\n",
       " Timestamp('2023-01-25 00:00:00'),\n",
       " Timestamp('2023-01-26 00:00:00')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2ff14ca6-518b-477e-bf2b-cae9621a2d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timestamp('2022-12-27 00:00:00'), Timestamp('2022-12-28 00:00:00'), Timestamp('2022-12-29 00:00:00'), Timestamp('2022-12-30 00:00:00'), Timestamp('2023-01-03 00:00:00'), Timestamp('2023-01-04 00:00:00'), Timestamp('2023-01-05 00:00:00'), Timestamp('2023-01-06 00:00:00'), Timestamp('2023-01-09 00:00:00'), Timestamp('2023-01-10 00:00:00'), Timestamp('2023-01-11 00:00:00'), Timestamp('2023-01-12 00:00:00'), Timestamp('2023-01-13 00:00:00'), Timestamp('2023-01-17 00:00:00'), Timestamp('2023-01-18 00:00:00'), Timestamp('2023-01-19 00:00:00'), Timestamp('2023-01-20 00:00:00'), Timestamp('2023-01-23 00:00:00'), Timestamp('2023-01-24 00:00:00'), Timestamp('2023-01-25 00:00:00'), Timestamp('2023-01-26 00:00:00')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gs://pmykola-streaming-projects/spg-stocks/dat...</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>2022-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gs://pmykola-streaming-projects/spg-stocks/dat...</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>2022-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gs://pmykola-streaming-projects/spg-stocks/dat...</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>2022-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>gs://pmykola-streaming-projects/spg-stocks/dat...</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename  year month day  \\\n",
       "11  gs://pmykola-streaming-projects/spg-stocks/dat...  2022    12  28   \n",
       "12  gs://pmykola-streaming-projects/spg-stocks/dat...  2022    12  29   \n",
       "13  gs://pmykola-streaming-projects/spg-stocks/dat...  2022    12  30   \n",
       "30  gs://pmykola-streaming-projects/spg-stocks/dat...  2023     1   3   \n",
       "\n",
       "         date  \n",
       "11 2022-12-28  \n",
       "12 2022-12-29  \n",
       "13 2022-12-30  \n",
       "30 2023-01-03  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://pmykola-streaming-projects/spg-stocks/data/auto_data_last_20221228_pull_time_12_28_16:10:5.csv', 'gs://pmykola-streaming-projects/spg-stocks/data/auto_data_last_20221229_pull_time_12_29_16:10:5.csv', 'gs://pmykola-streaming-projects/spg-stocks/data/auto_data_last_20221230_pull_time_12_30_16:10:5.csv', 'gs://pmykola-streaming-projects/spg-stocks/data/auto_data_last_202313_pull_time_1_3_16:10:7.csv']\n",
      "time: 0.5465264320373535 sec\n",
      "time: 2.4644689559936523 sec\n",
      "time: 2.4690635204315186 sec\n",
      "time: 2.47733736038208 sec\n",
      "time: 2.626012086868286 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 observations this day\n",
      "time: 2.8970043659210205 sec\n"
     ]
    }
   ],
   "source": [
    "# this part implements for loop to do perfeval for each date in range\n",
    "print(dates)\n",
    "\n",
    "# for last_day in dates:\n",
    "    \n",
    "    \n",
    "\n",
    "last_day = dates[4]\n",
    "\n",
    "mask = [x <= last_day for x in list(tempdf.date)]\n",
    "tempdf = tempdf[mask]\n",
    "tempdf = tempdf.tail(4)\n",
    "display(tempdf)\n",
    "\n",
    "datafiles = list(tempdf.filename)\n",
    "print(datafiles)\n",
    "df = pd.read_csv(datafiles[0])\n",
    "print(f'time: {time.time()-time2} sec')\n",
    "\n",
    "df_new = pd.DataFrame(columns = df.columns)\n",
    "for file in datafiles:\n",
    "    temp_df = pd.read_csv(file)\n",
    "    df_new = pd.concat([df_new, temp_df], axis=0)\n",
    "print(f'time: {time.time()-time2} sec')\n",
    "\n",
    "# remove duplicates\n",
    "df_new.reset_index(inplace=True, drop=True)\n",
    "df_new.drop_duplicates(inplace=True)\n",
    "df_new.Datetime = pd.to_datetime(df_new.Datetime)\n",
    "df_new.sort_values(by='Datetime')\n",
    "print(f'time: {time.time()-time2} sec')\n",
    "\n",
    "df = df_new\n",
    "df.Datetime = pd.to_datetime(df.Datetime)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.sort_values(by='Datetime')\n",
    "\n",
    "df['time'] = df.Datetime.dt.time\n",
    "df['date'] = df.Datetime.dt.date\n",
    "\n",
    "df = df.fillna(method='ffill')\n",
    "dayclose = df[df.time==datetime.time(15, 58, 0)]\n",
    "dayopen = df[df.time==datetime.time(9, 30, 0)]\n",
    "dayopen.reset_index(drop=True, inplace=True)\n",
    "dayclose.reset_index(drop=True, inplace=True)\n",
    "dayclose.sort_values(by='date')\n",
    "print(f'time: {time.time()-time2} sec')\n",
    "\n",
    "### now i wanna do feature engineering for all assets \n",
    "\n",
    "asset_list = ['Spx', 'Nasdaq', 'Russel', 'EMXC', 'EEMA', 'EEM', 'VTHR']\n",
    "\n",
    "for asset in asset_list:\n",
    "\n",
    "    df[asset + '_ret'] = 100*(df[asset]/df[asset].shift(1)-1)\n",
    "    df['s_' + asset + '_ret_1prd'] = (100*(df[asset]/df[asset].shift(1)-1)).shift(1)\n",
    "    df['s_' + asset + '_ret_2prd'] = (100*(df[asset]/df[asset].shift(2)-1)).shift(1)\n",
    "    df['s_' + asset + '_ret_4prd'] = (100*(df[asset]/df[asset].shift(4)-1)).shift(1)\n",
    "    # display(df.shape, df.head(5))\n",
    "\n",
    "    df.loc[df.time < datetime.time(9, 32, 0), 's_' + asset + '_1prd'] = np.nan\n",
    "    df.loc[df.time < datetime.time(9, 33, 0), 's_' + asset + '_2prd'] = np.nan\n",
    "    df.loc[df.time < datetime.time(9, 35, 0), 's_' + asset + '_4prd'] = np.nan\n",
    "\n",
    "    dayopen.rename(columns={asset:asset+'_open'}, inplace=True)\n",
    "    # dayopen.head()\n",
    "    dayclose.rename(columns={asset:asset+'_close'}, inplace=True)\n",
    "    dayclose_l1 = dayclose.copy()\n",
    "    dayclose_l2 = dayclose.copy()\n",
    "    dayclose_l1[asset+'_close_l1'] = dayclose_l1[asset+'_close'].shift(1)\n",
    "    dayclose_l2[asset+'_close_l2'] = dayclose_l2[asset+'_close'].shift(2)\n",
    "\n",
    "    df = pd.merge(df, dayopen[['date', asset + '_open']], on=['date'], how='left')\n",
    "    df = pd.merge(df, dayclose_l1[['date', asset + '_close_l1']], on=['date'], how='left')\n",
    "    df = pd.merge(df, dayclose_l2[['date', asset + '_close_l2']], on=['date'], how='left')\n",
    "\n",
    "    df['s_' + asset + '_ret_open'] = (100*(df[asset]/df[asset + '_open']-1)).shift(1)\n",
    "    df['s_' + asset + '_ret_close1'] = (100*(df[asset]/df[asset + '_close_l1']-1)).shift(1)\n",
    "    df['s_' + asset + '_ret_close2'] = (100*(df[asset]/df[asset + '_close_l2']-1)).shift(1)\n",
    "\n",
    "    cols_todrop = [x for x in list(df.columns) if asset in x and 'ret' not in x]\n",
    "    df.drop(columns = cols_todrop, inplace=True)\n",
    "print(f'time: {time.time()-time2} sec')\n",
    "\n",
    "### do prediction ###\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket_name='pmykola-streaming-projects'\n",
    "model_path='spg-stocks/artifacts/en_model.pkl'\n",
    "\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "blob = bucket.blob(model_path)\n",
    "model_file = BytesIO()\n",
    "blob.download_to_file(model_file)\n",
    "trained_model=joblib.load(model_file)\n",
    "\n",
    "# df.date.max()\n",
    "this_day = df.loc[df.date == df.date.max()]\n",
    "print(f'{this_day.shape[0]} observations this day')\n",
    "X = this_day.copy()\n",
    "X.drop(columns = ['Datetime',\n",
    "              'time', \n",
    "              'date', \n",
    "              'Spx_ret', \n",
    "              'Nasdaq_ret', \n",
    "              'Russel_ret', \n",
    "              'EEMA_ret', \n",
    "              'EEM_ret', \n",
    "              'EMXC_ret', \n",
    "              'VXUS_ret', \n",
    "              'VTHR_ret'], \n",
    "              inplace=True,\n",
    "              errors = 'ignore')\n",
    "\n",
    "if(X.count().sum() < X.shape[1]):\n",
    "    print(f'''There are {X.shape[1] - X.count().sum()} missing values. \n",
    "          There will be an error''')\n",
    "\n",
    "y = this_day.VTHR_ret\n",
    "y_hat = trained_model.predict(X)\n",
    "\n",
    "model_rmse = mean_squared_error(y, y_hat)\n",
    "constant_rmse = mean_squared_error(y, np.zeros(len(y)))\n",
    "\n",
    "performance = pd.DataFrame([[100*(r2_score(y, y_hat)), model_rmse, constant_rmse, 100*(1-model_rmse/constant_rmse)]], \n",
    "                      columns = ['R2', 'model_rmse', 'constant_rmse', 'rmse_improvement'])\n",
    "performance['date'] = df.date.max()\n",
    "print(f'time: {time.time()-time2} sec')\n",
    "\n",
    "file_name = 'spg-stocks/artifacts/performance-data/' + \\\n",
    "'m1_performance_' + \\\n",
    "str(df.date.max().year) + \\\n",
    "str(df.date.max().month) + \\\n",
    "str(df.date.max().day) + \\\n",
    "'_pull_time_' + \\\n",
    "now_time + \\\n",
    "'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "36074405-71cd-4410-a8bc-470c6a1a157f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>model_rmse</th>\n",
       "      <th>constant_rmse</th>\n",
       "      <th>rmse_improvement</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.049659</td>\n",
       "      <td>0.009579</td>\n",
       "      <td>0.011153</td>\n",
       "      <td>14.107696</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          R2  model_rmse  constant_rmse  rmse_improvement        date\n",
       "0  14.049659    0.009579       0.011153         14.107696  2023-01-03"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c75d92-1083-4d16-8d07-fddba6270d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dd3ef36c-710d-41f5-ba31-2aa9666d186e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timestamp('2022-12-27 00:00:00'), Timestamp('2022-12-28 00:00:00'), Timestamp('2022-12-29 00:00:00'), Timestamp('2022-12-30 00:00:00'), Timestamp('2023-01-03 00:00:00'), Timestamp('2023-01-04 00:00:00'), Timestamp('2023-01-05 00:00:00'), Timestamp('2023-01-06 00:00:00'), Timestamp('2023-01-09 00:00:00'), Timestamp('2023-01-10 00:00:00'), Timestamp('2023-01-11 00:00:00'), Timestamp('2023-01-12 00:00:00'), Timestamp('2023-01-13 00:00:00'), Timestamp('2023-01-17 00:00:00'), Timestamp('2023-01-18 00:00:00'), Timestamp('2023-01-19 00:00:00'), Timestamp('2023-01-20 00:00:00'), Timestamp('2023-01-23 00:00:00'), Timestamp('2023-01-24 00:00:00'), Timestamp('2023-01-25 00:00:00'), Timestamp('2023-01-26 00:00:00')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gs://pmykola-streaming-projects/spg-stocks/dat...</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>2022-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gs://pmykola-streaming-projects/spg-stocks/dat...</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>2022-12-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gs://pmykola-streaming-projects/spg-stocks/dat...</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>2022-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gs://pmykola-streaming-projects/spg-stocks/dat...</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>2022-12-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename  year month day  \\\n",
       "8   gs://pmykola-streaming-projects/spg-stocks/dat...  2022    12  22   \n",
       "9   gs://pmykola-streaming-projects/spg-stocks/dat...  2022    12  23   \n",
       "10  gs://pmykola-streaming-projects/spg-stocks/dat...  2022    12  27   \n",
       "11  gs://pmykola-streaming-projects/spg-stocks/dat...  2022    12  28   \n",
       "\n",
       "         date  \n",
       "8  2022-12-22  \n",
       "9  2022-12-23  \n",
       "10 2022-12-27  \n",
       "11 2022-12-28  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://pmykola-streaming-projects/spg-stocks/data/auto_data_last_20221222_pull_time_12_22_16:10:5.csv', 'gs://pmykola-streaming-projects/spg-stocks/data/auto_data_last_20221223_pull_time_12_23_16:10:5.csv', 'gs://pmykola-streaming-projects/spg-stocks/data/auto_data_last_20221227_pull_time_12_27_16:10:8.csv', 'gs://pmykola-streaming-projects/spg-stocks/data/auto_data_last_20221228_pull_time_12_28_16:10:5.csv']\n",
      "time: 1.109525203704834 sec\n",
      "time: 5.356024742126465 sec\n",
      "time: 5.3604090213775635 sec\n",
      "time: 5.368605375289917 sec\n",
      "time: 5.514732599258423 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 observations this day\n",
      "time: 6.145131587982178 sec\n",
      "Upload to Cloud Storage complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response Success: spg-stocks/artifacts/performance-data/m1_performance_20221228_pull_time_1_26_20:31:30.csv upload complete. Total time: 13.792sec\n",
      "time: 12.234391450881958 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "storage_client = storage.Client()\n",
    "bucket_name = 'pmykola-streaming-projects'\n",
    "BUCKET = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "blob = BUCKET.blob(file_name)\n",
    "blob.upload_from_string(performance.to_csv(), 'text/csv')\n",
    "print('Upload to Cloud Storage complete.')\n",
    "\n",
    "project_id = 'valid-heuristic-369117'\n",
    "bucket_path = 'gs://pmykola-streaming-projects/spg-stocks/artifacts/performance-data/'\n",
    "table_id = 'spg_stocks.daily_performance'\n",
    "\n",
    "performance.rename(columns={'date':'ddate'}, inplace=True)\n",
    "pandas_gbq.to_gbq(performance, table_id, project_id=project_id, if_exists='append')\n",
    "\n",
    "result = ('Success: ' + file_name + ' upload complete. ' + \n",
    "'Total time: ' + str(time.time()-time0)[:6] + 'sec')\n",
    "print('response', result)\n",
    "print(f'time: {time.time()-time2} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c93975-c6ac-41d5-a450-441b1eda23d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "060bdd62-3762-461a-ae78-1c731c956ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-27 00:00:00\n",
      "2022-12-28 00:00:00\n",
      "2022-12-29 00:00:00\n",
      "2022-12-30 00:00:00\n",
      "2023-01-03 00:00:00\n",
      "2023-01-04 00:00:00\n",
      "2023-01-05 00:00:00\n",
      "2023-01-06 00:00:00\n",
      "2023-01-09 00:00:00\n",
      "2023-01-10 00:00:00\n",
      "2023-01-11 00:00:00\n",
      "2023-01-12 00:00:00\n",
      "2023-01-13 00:00:00\n",
      "2023-01-17 00:00:00\n",
      "2023-01-18 00:00:00\n",
      "2023-01-19 00:00:00\n",
      "2023-01-20 00:00:00\n",
      "2023-01-23 00:00:00\n",
      "2023-01-24 00:00:00\n",
      "2023-01-25 00:00:00\n",
      "2023-01-26 00:00:00\n"
     ]
    }
   ],
   "source": [
    "for last_day in dates:\n",
    "    print(last_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6c74a-8745-4fcf-a0d5-9b5da06cbdab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m103"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
